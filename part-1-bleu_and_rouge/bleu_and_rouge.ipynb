{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# BLEU and ROUGE Evaluation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mekjr1/evaluating_llms_in_practice/blob/master/part-1-bleu_and_rouge/bleu_and_rouge.ipynb?hl=en#runtime_type=gpu)\n",
    "\n",
    "This notebook demonstrates how to evaluate text summarization models using BLEU and ROUGE metrics. The notebook is configured to use GPU runtime for faster model inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a70225",
   "metadata": {},
   "source": [
    "## Why Traditional Accuracy Metrics Fail for Text Generation\n",
    "\n",
    "When evaluating text generation models, we can't simply use classification accuracy because:\n",
    "\n",
    "### Classification vs Generation Tasks\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚        Classification           â”‚        Text Generation          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Input: \"I love this movie\"      â”‚ Input: Long article text        â”‚\n",
    "â”‚ Output: [Positive, Negative]    â”‚ Output: \"Scientists discover...\" â”‚\n",
    "â”‚ Ground Truth: Positive          â”‚ Reference: \"Researchers found...\" â”‚\n",
    "â”‚                                 â”‚                                 â”‚\n",
    "â”‚ âœ… Exact Match = 100% Accuracy  â”‚ âŒ Exact Match = 0% Accuracy    â”‚\n",
    "â”‚ âŒ Different = 0% Accuracy      â”‚ But both summaries are good! ğŸ¤” â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**The Problem**: Two different but equally valid summaries would get 0% accuracy score, even if they're both excellent summaries that capture the same key information.\n",
    "\n",
    "**The Solution**: We need metrics that measure **semantic similarity** and **content overlap** rather than exact matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting datasets\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting evaluate\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25l  Installing build dependencies ... \u001b[?25l-done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-done\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25done\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-done\n",
      "\u001b[?25done\n",
      "\u001b[?25hCollecting nltk\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-6.3.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting plotly\n",
      "  Using cached plotly-6.3.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mekjr1/personal/teachings/evaluating_llms_in_practice/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mekjr1/personal/teachings/evaluating_llms_in_practice/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "  Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting absl-py (from rouge-score)\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/mekjr1/personal/teachings/evaluating_llms_in_practice/.venv/lib/python3.12/site-packages (from rouge-score) (1.17.0)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/mekjr1/personal/teachings/evaluating_llms_in_practice/.venv/lib/python3.12/site-packages (from rouge-score) (1.17.0)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (111 kB)\n",
      "  Downloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (111 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mekjr1/personal/teachings/evaluating_llms_in_practice/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mekjr1/personal/teachings/evaluating_llms_in_practice/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Using cached narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/11.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/563.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.10.6-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached plotly-6.3.0-py3-none-any.whl (9.8 MB)\n",
      "Using cached plotly-6.3.0-py3-none-any.whl (9.8 MB)\n",
      "Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Using cached pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Using cached multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/4.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading fonttools-4.60.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/807.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (pyproject.toml) ... \u001b[?25lBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (pyproject.toml) ... \u001b[?25l-done\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=008f991cee61018103e10097e4e4841705d3a59ce3de6a4fa97e4de0707903f2\n",
      "  Stored in directory: /home/mekjr1/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "\bdone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=008f991cee61018103e10097e4e4841705d3a59ce3de6a4fa97e4de0707903f2\n",
      "  Stored in directory: /home/mekjr1/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, safetensors, regex, pyyaml, pyparsing, pyarrow, propcache, pillow, numpy, narwhals, multidict, kiwisolver, joblib, idna, hf-xet, fsspec, frozenlist, fonttools, filelock, dill, cycler, click, charset_normalizer, certifi, attrs, aiohappyeyeballs, absl-py, yarl, requests, plotly, pandas, nltk, multiprocess, contourpy, aiosignal, rouge-score, matplotlib, huggingface-hub, aiohttp, tokenizers, seaborn, transformers, datasets, evaluate\n",
      "\u001b[?25lInstalling collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, safetensors, regex, pyyaml, pyparsing, pyarrow, propcache, pillow, numpy, narwhals, multidict, kiwisolver, joblib, idna, hf-xet, fsspec, frozenlist, fonttools, filelock, dill, cycler, click, charset_normalizer, certifi, attrs, aiohappyeyeballs, absl-py, yarl, requests, plotly, pandas, nltk, multiprocess, contourpy, aiosignal, rouge-score, matplotlib, huggingface-hub, aiohttp, tokenizers, seaborn, transformers, datasets, evaluate\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49/49\u001b[0m [evaluate]evaluate]datasets]ers]ub]]r]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49/49\u001b[0m [evaluate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 click-8.3.0 contourpy-1.3.3 cycler-0.12.1 datasets-4.1.1 dill-0.4.0 evaluate-0.4.6 filelock-3.19.1 fonttools-4.60.0 frozenlist-1.7.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.1 idna-3.10 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.6 multidict-6.6.4 multiprocess-0.70.16 narwhals-2.5.0 nltk-3.9.1 numpy-2.3.3 pandas-2.3.2 pillow-11.3.0 plotly-6.3.0 propcache-0.3.2 pyarrow-21.0.0 pyparsing-3.2.5 pytz-2025.2 pyyaml-6.0.3 regex-2025.9.18 requests-2.32.5 rouge-score-0.1.2 safetensors-0.6.2 seaborn-0.13.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.56.2 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Successfully installed absl-py-2.3.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 click-8.3.0 contourpy-1.3.3 cycler-0.12.1 datasets-4.1.1 dill-0.4.0 evaluate-0.4.6 filelock-3.19.1 fonttools-4.60.0 frozenlist-1.7.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.1 idna-3.10 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.6 multidict-6.6.4 multiprocess-0.70.16 narwhals-2.5.0 nltk-3.9.1 numpy-2.3.3 pandas-2.3.2 pillow-11.3.0 plotly-6.3.0 propcache-0.3.2 pyarrow-21.0.0 pyparsing-3.2.5 pytz-2025.2 pyyaml-6.0.3 regex-2025.9.18 requests-2.32.5 rouge-score-0.1.2 safetensors-0.6.2 seaborn-0.13.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.56.2 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate rouge-score nltk matplotlib seaborn plotly pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mevaluate\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e7384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small subset of CNN/DailyMail dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:20]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two summarization models\n",
    "model_a = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "model_b = pipeline(\"summarization\", model=\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one article\n",
    "article = dataset[0][\"article\"]\n",
    "reference = dataset[0][\"highlights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-summaries",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_a = model_a(article, max_length=60, min_length=20, do_sample=False)[0][\"summary_text\"]\n",
    "summary_b = model_b(article, max_length=60, min_length=20, do_sample=False)[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-summaries",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reference:\", reference)\n",
    "print(\"\\nModel A:\", summary_a)\n",
    "print(\"\\nModel B:\", summary_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "from IPython.display import HTML, display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba05085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_overlaps(reference, candidate, title):\n",
    "    \"\"\"Highlight overlapping words between reference and candidate text\"\"\"\n",
    "    # Simple word tokenization\n",
    "    ref_words = set(re.findall(r'\\b\\w+\\b', reference.lower()))\n",
    "    cand_words = re.findall(r'\\b\\w+\\b', candidate.lower())\n",
    "    \n",
    "    # Create highlighted version\n",
    "    highlighted = []\n",
    "    for word in candidate.split():\n",
    "        clean_word = re.sub(r'[^\\w]', '', word.lower())\n",
    "        if clean_word in ref_words:\n",
    "            highlighted.append(f\"<span style='background-color: #90EE90; padding: 2px; margin: 1px; border-radius: 3px;'>{word}</span>\")\n",
    "        else:\n",
    "            highlighted.append(word)\n",
    "    \n",
    "    overlap_count = sum(1 for word in cand_words if word in ref_words)\n",
    "    overlap_ratio = overlap_count / len(cand_words) if cand_words else 0\n",
    "    \n",
    "    return \" \".join(highlighted), overlap_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c35c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for both summaries\n",
    "print(\"ğŸ” N-gram Overlap Analysis\")\n",
    "print(\"=\" * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_display = f\"<div style='padding: 15px; background-color: #f0f8ff; border-left: 4px solid #4682b4; margin: 10px 0;'><strong>Reference Summary:</strong><br>{reference}</div>\"\n",
    "\n",
    "summary_a_highlighted, overlap_a = highlight_overlaps(reference, summary_a, \"Model A\")\n",
    "summary_b_highlighted, overlap_b = highlight_overlaps(reference, summary_b, \"Model B\")\n",
    "\n",
    "model_a_display = f\"\"\"\n",
    "<div style='padding: 15px; background-color: #f9f9f9; border-left: 4px solid #32cd32; margin: 10px 0;'>\n",
    "<strong>Model A Summary (Word Overlap: {overlap_a:.1%}):</strong><br>\n",
    "{summary_a_highlighted}\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "model_b_display = f\"\"\"\n",
    "<div style='padding: 15px; background-color: #f9f9f9; border-left: 4px solid #ff6347; margin: 10px 0;'>\n",
    "<strong>Model B Summary (Word Overlap: {overlap_b:.1%}):</strong><br>\n",
    "{summary_b_highlighted}\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "legend = \"\"\"\n",
    "<div style='padding: 10px; background-color: #fffacd; border: 1px solid #ddd; margin: 10px 0; border-radius: 5px;'>\n",
    "<strong>Legend:</strong> <span style='background-color: #90EE90; padding: 2px; margin: 1px; border-radius: 3px;'>Highlighted words</span> appear in both the reference and candidate summary\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(ref_display + model_a_display + model_b_display + legend))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e01fcf",
   "metadata": {},
   "source": [
    "## BLEU vs ROUGE: Understanding the Metrics\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; margin: 20px 0;\">\n",
    "<table style=\"border-collapse: collapse; width: 100%; max-width: 800px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);\">\n",
    "  <thead>\n",
    "    <tr style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;\">\n",
    "      <th style=\"padding: 15px; text-align: left; font-weight: 600;\">Aspect</th>\n",
    "      <th style=\"padding: 15px; text-align: center; font-weight: 600;\">BLEU</th>\n",
    "      <th style=\"padding: 15px; text-align: center; font-weight: 600;\">ROUGE</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr style=\"background-color: #f8f9fa;\">\n",
    "      <td style=\"padding: 15px; font-weight: 500; border-right: 2px solid #e9ecef;\">ğŸ“ <strong>Primary Focus</strong></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">Precision (exact matches)</td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">Recall (coverage)</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #ffffff;\">\n",
    "      <td style=\"padding: 15px; font-weight: 500; border-right: 2px solid #e9ecef;\">ğŸ” <strong>What it Measures</strong></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">N-gram precision<br><em>(How many generated words are correct?)</em></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">N-gram recall<br><em>(How much reference content is captured?)</em></td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f8f9fa;\">\n",
    "      <td style=\"padding: 15px; font-weight: 500; border-right: 2px solid #e9ecef;\">ğŸ¯ <strong>Best For</strong></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">Machine Translation</td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">Text Summarization</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #ffffff;\">\n",
    "      <td style=\"padding: 15px; font-weight: 500; border-right: 2px solid #e9ecef;\">ğŸ“Š <strong>Score Range</strong></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">0.0 - 1.0<br><em>(Higher = Better)</em></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">0.0 - 1.0<br><em>(Higher = Better)</em></td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #f8f9fa;\">\n",
    "      <td style=\"padding: 15px; font-weight: 500; border-right: 2px solid #e9ecef;\">âš–ï¸ <strong>Key Strength</strong></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">Penalizes hallucinations</td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">Rewards content coverage</td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #ffffff;\">\n",
    "      <td style=\"padding: 15px; font-weight: 500; border-right: 2px solid #e9ecef;\">âš ï¸ <strong>Limitation</strong></td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">May penalize valid paraphrases</td>\n",
    "      <td style=\"padding: 15px; text-align: center;\">May reward keyword stuffing</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "> **ğŸ’¡ Pro Tip**: Use both metrics together! BLEU catches fluency issues while ROUGE ensures content coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compute-bleu",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bleu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m bleu_a = \u001b[43mbleu\u001b[49m.compute(predictions=[summary_a], references=[[reference]])\n\u001b[32m      2\u001b[39m bleu_b = bleu.compute(predictions=[summary_b], references=[[reference]])\n",
      "\u001b[31mNameError\u001b[39m: name 'bleu' is not defined"
     ]
    }
   ],
   "source": [
    "bleu_a = bleu.compute(predictions=[summary_a], references=[[reference]])\n",
    "bleu_b = bleu.compute(predictions=[summary_b], references=[[reference]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_a = rouge.compute(predictions=[summary_a], references=[reference])\n",
    "rouge_b = rouge.compute(predictions=[summary_b], references=[reference])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel A BLEU:\", bleu_a)\n",
    "print(\"Model B BLEU:\", bleu_b)\n",
    "print(\"\\nModel A ROUGE:\", rouge_a)\n",
    "print(\"Model B ROUGE:\", rouge_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization of results\n",
    "plt.style.use('default')\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('ğŸ“Š BLEU & ROUGE Evaluation Results', fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "# Color scheme\n",
    "colors = ['#3498db', '#e74c3c']  # Blue for Model A, Red for Model B\n",
    "model_names = ['Model A\\n(DistilBART)', 'Model B\\n(BART-base)']\n",
    "\n",
    "# 1. BLEU Scores Comparison\n",
    "bleu_scores = [bleu_a['bleu'], bleu_b['bleu']]\n",
    "bars1 = ax1.bar(model_names, bleu_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_title('ğŸ¯ BLEU Scores', fontsize=14, fontweight='bold', pad=20)\n",
    "ax1.set_ylabel('BLEU Score', fontsize=12)\n",
    "ax1.set_ylim(0, max(bleu_scores) * 1.2)\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars1, bleu_scores):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "             f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 2. ROUGE-1 Comparison\n",
    "rouge1_scores = [rouge_a['rouge1'], rouge_b['rouge1']]\n",
    "bars2 = ax2.bar(model_names, rouge1_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_title('ğŸ” ROUGE-1 Scores', fontsize=14, fontweight='bold', pad=20)\n",
    "ax2.set_ylabel('ROUGE-1 Score', fontsize=12)\n",
    "ax2.set_ylim(0, max(rouge1_scores) * 1.2)\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "for bar, score in zip(bars2, rouge1_scores):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 3. ROUGE-2 Comparison\n",
    "rouge2_scores = [rouge_a['rouge2'], rouge_b['rouge2']]\n",
    "bars3 = ax3.bar(model_names, rouge2_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_title('ğŸ“ ROUGE-2 Scores', fontsize=14, fontweight='bold', pad=20)\n",
    "ax3.set_ylabel('ROUGE-2 Score', fontsize=12)\n",
    "ax3.set_ylim(0, max(rouge2_scores) * 1.2)\n",
    "ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "for bar, score in zip(bars3, rouge2_scores):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "             f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# 4. ROUGE-L Comparison\n",
    "rougeL_scores = [rouge_a['rougeL'], rouge_b['rougeL']]\n",
    "bars4 = ax4.bar(model_names, rougeL_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax4.set_title('ğŸ“ ROUGE-L Scores', fontsize=14, fontweight='bold', pad=20)\n",
    "ax4.set_ylabel('ROUGE-L Score', fontsize=12)\n",
    "ax4.set_ylim(0, max(rougeL_scores) * 1.2)\n",
    "ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "for bar, score in zip(bars4, rougeL_scores):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“‹ SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': ['BLEU', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L'],\n",
    "    'Model A (DistilBART)': [f\"{bleu_a['bleu']:.3f}\", f\"{rouge_a['rouge1']:.3f}\", \n",
    "                            f\"{rouge_a['rouge2']:.3f}\", f\"{rouge_a['rougeL']:.3f}\"],\n",
    "    'Model B (BART-base)': [f\"{bleu_b['bleu']:.3f}\", f\"{rouge_b['rouge1']:.3f}\", \n",
    "                           f\"{rouge_b['rouge2']:.3f}\", f\"{rouge_b['rougeL']:.3f}\"],\n",
    "    'Winner': []\n",
    "}\n",
    "\n",
    "# Determine winners\n",
    "metrics_scores = [(bleu_a['bleu'], bleu_b['bleu']), (rouge_a['rouge1'], rouge_b['rouge1']), \n",
    "                  (rouge_a['rouge2'], rouge_b['rouge2']), (rouge_a['rougeL'], rouge_b['rougeL'])]\n",
    "\n",
    "for a_score, b_score in metrics_scores:\n",
    "    if a_score > b_score:\n",
    "        summary_data['Winner'].append('ğŸ† Model A')\n",
    "    elif b_score > a_score:\n",
    "        summary_data['Winner'].append('ğŸ† Model B')\n",
    "    else:\n",
    "        summary_data['Winner'].append('ğŸ¤ Tie')\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ab1e0",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **ğŸš« Why Accuracy Fails**: Traditional classification accuracy doesn't work for text generation because multiple valid outputs exist for the same input.\n",
    "\n",
    "2. **ğŸ” BLEU vs ROUGE**: \n",
    "   - **BLEU** focuses on precision (avoiding hallucinations)\n",
    "   - **ROUGE** focuses on recall (capturing key information)\n",
    "\n",
    "3. **ğŸ“Š Visual Analysis**: The charts above show how different models perform across various metrics, helping us make informed decisions.\n",
    "\n",
    "4. **ğŸ’¡ Best Practices**: \n",
    "   - Always use multiple metrics together\n",
    "   - Consider the specific task (translation vs summarization)\n",
    "   - Look at both word-level and semantic similarity\n",
    "\n",
    "### Next Steps\n",
    "- Try with different models and datasets\n",
    "- Explore newer metrics like BERTScore or METEOR\n",
    "- Consider human evaluation for critical applications\n",
    "\n",
    "---\n",
    "*This notebook demonstrates fundamental concepts in NLP evaluation. The visual approach makes complex metrics more intuitive and actionable.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
